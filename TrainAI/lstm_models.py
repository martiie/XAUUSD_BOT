# =============================
# GOLD PRICE LSTM TRAINER (SAVE MODEL + SCALER)
# =============================

import os
import numpy as np
import pandas as pd
from datetime import datetime
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import joblib  # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å/‡πÇ‡∏´‡∏•‡∏î scaler

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


def train_gold_lstm(
    csv_path,
    save_model_path="gold_lstm_model.keras",
    save_scaler_path="gold_scaler.pkl",
    epochs=25,
    batch_size=32
):
    """
    ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥
    Parameters:
        csv_path: str ‚Äî path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ä‡πà‡∏ô gold_data.csv)
        save_model_path: str ‚Äî path ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (.keras ‡∏´‡∏£‡∏∑‡∏≠ .h5)
        save_scaler_path: str ‚Äî path ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å scaler (.pkl)
    Return:
        model, scaler, rmse
    """

    # 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    data = pd.read_csv(csv_path)
    data = data.rename(columns={
        'Open': 'open',
        'Close': 'close',
        'High': 'high',
        'Low': 'low',
        'Datetime': 'date',
        'Volume': 'volume'
    })
    data['date'] = pd.to_datetime(data['date'])
    close_data = data[['close']].values

    # 2Ô∏è‚É£ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(close_data)

    training_ratio = 0.95
    training_data_len = int(len(scaled_data) * training_ratio)
    train_data = scaled_data[:training_data_len]
    test_data = scaled_data[training_data_len - 30:]

    def create_sequences(data, window_size=30):
        X, y = [], []
        for i in range(window_size, len(data)):
            X.append(data[i-window_size:i, 0])
            y.append(data[i, 0])
        return np.array(X), np.array(y)

    X_train, y_train = create_sequences(train_data)
    X_test, y_test = create_sequences(test_data)

    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

    # 3Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM
    model = keras.models.Sequential([
        keras.layers.LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], 1)),
        keras.layers.LSTM(64, return_sequences=False),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(1)
    ])

    model.compile(optimizer='adam', loss='mae', metrics=[keras.metrics.RootMeanSquaredError()])

    # 4Ô∏è‚É£ ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model.fit(X_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=1)

    # 5Ô∏è‚É£ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
    predictions = model.predict(X_test)
    predictions = scaler.inverse_transform(predictions)
    real_prices = close_data[training_data_len:]
    rmse = np.sqrt(mean_squared_error(real_prices, predictions))
    print(f"‚úÖ RMSE: {rmse:.2f}")

    # 6Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Scaler
    model.save(save_model_path)
    joblib.dump(scaler, save_scaler_path)

    print(f"üíæ Model saved to: {save_model_path}")
    print(f"üíæ Scaler saved to: {save_scaler_path}")

    return model, scaler, rmse

def continue_train_gold_lstm(
    csv_path,
    model_path="gold_lstm_model.keras",
    scaler_path="gold_scaler.pkl",
    epochs=50,
    batch_size=32
):
    """
    ‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ scaler ‡πÄ‡∏î‡∏¥‡∏°
    """

    # -------------------------
    # 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ scaler ‡πÄ‡∏î‡∏¥‡∏°
    # -------------------------
    model = keras.models.load_model(model_path)
    scaler = joblib.load(scaler_path)

    # -------------------------
    # 2Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
    # -------------------------
    data = pd.read_csv(csv_path)
    data['Datetime'] = pd.to_datetime(data['Datetime'])
    close_data = data[['Close']].values

    scaled_data = scaler.transform(close_data)

    def create_sequences(data, window_size=30):
        X, y = [], []
        for i in range(window_size, len(data)):
            X.append(data[i-window_size:i, 0])
            y.append(data[i, 0])
        return np.array(X), np.array(y)

    X, y = create_sequences(scaled_data)
    X = X.reshape((X.shape[0], X.shape[1], 1))

    # -------------------------
    # 3Ô∏è‚É£ ‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°
    # -------------------------
    print("üß© Continue training existing LSTM model...")
    model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=1)

    # -------------------------
    # 4Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ scaler ‡∏Å‡∏•‡∏±‡∏ö
    # -------------------------
    model.save(model_path)
    joblib.dump(scaler, scaler_path)
    print("üíæ Updated model & scaler saved.")

    return model, scaler

import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
import joblib
from datetime import timedelta

def predict_gold_prices_from_csv(csv_path, model_path, scaler_path, n_future=3, window_size=120):
    """
    ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡πÑ‡∏õ n_future ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤:
        - data: DataFrame ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
        - forecast_df: DataFrame ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á ¬±1%
    """
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ scaler
    model = load_model(model_path)
    scaler = joblib.load(scaler_path)

    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    data = pd.read_csv(csv_path)
    if 'Datetime' not in data.columns or 'Close' not in data.columns:
        raise ValueError("CSV ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Datetime' ‡πÅ‡∏•‡∏∞ 'Close'")

    data['Datetime'] = pd.to_datetime(data['Datetime'])
    data = data.sort_values('Datetime').reset_index(drop=True)

    close_prices = data[['Close']].values

    # ‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    scaled_data = scaler.transform(close_prices)

    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏£‡∏≤‡∏¢‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
    def forecast_future(model, data_scaled, n_future, window_size):
        preds = []
        last_window = data_scaled[-window_size:].reshape(1, window_size, 1)
        for _ in range(n_future):
            pred = model.predict(last_window, verbose=0)
            preds.append(pred[0, 0])
            last_window = np.append(last_window[:, 1:, :], [[[pred[0, 0]]]], axis=1)
        return np.array(preds).reshape(-1, 1)

    window_size = min(window_size, len(scaled_data))

    future_scaled = forecast_future(model, scaled_data, n_future=n_future, window_size=window_size)
    future_pred = scaler.inverse_transform(future_scaled)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏£‡∏≤‡∏¢‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
    last_dt = data['Datetime'].iloc[-1]
    future_dates = [last_dt + timedelta(hours=i+1) for i in range(n_future)]

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    forecast_df = pd.DataFrame({
        "Datetime": future_dates,
        "Predicted_Price": future_pred.flatten()
    })

    forecast_df["Lower_Bound (-1%)"] = forecast_df["Predicted_Price"] * 0.99
    forecast_df["Upper_Bound (+1%)"] = forecast_df["Predicted_Price"] * 1.01

    return data, forecast_df

import matplotlib.pyplot as plt

def plot_gold_prediction(data, forecast_df, last_history=60):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡∏à‡∏£‡∏¥‡∏á‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
    - data: DataFrame ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
    - forecast_df: DataFrame ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
    - last_history: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á (default 60)
    """
    plt.figure(figsize=(12,6))

    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
    plt.plot(data['Datetime'].iloc[-last_history:], 
             data['Close'].iloc[-last_history:], 
             label='Actual (last history)', color='blue')

    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
    plt.plot(forecast_df["Datetime"], forecast_df["Predicted_Price"], '--o', color='red', label='Predicted')

    # Margin ¬±1%
    plt.fill_between(forecast_df["Datetime"],
                     forecast_df["Lower_Bound (-1%)"],
                     forecast_df["Upper_Bound (+1%)"],
                     color='red', alpha=0.2, label='Margin ¬±1%')

    plt.xlabel("Datetime")
    plt.ylabel("Price (USD)")
    plt.title(f"üìà predict gold in {len(forecast_df)} hours")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("Data/gold_price_prediction.png")
    print("üíæ Graph saved to: Data/gold_price_prediction.png")
